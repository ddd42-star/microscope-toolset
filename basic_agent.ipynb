{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic implementation of an agent using Litemind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make sure text completion works with base OpenAI wrapper (not using litemind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Endless calls unwind,  \\nFunctions within functions,  \\nLooping back to start.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├ OpenAI API key is valid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dario\\anaconda3\\envs\\masterThesis\\lib\\site-packages\\litemind\\apis\\providers\\ollama\\ollama_api.py\", line 62, in __init__\n",
      "    self._model_list = _get_ollama_models_list(self.client)\n",
      "  File \"c:\\Users\\dario\\anaconda3\\envs\\masterThesis\\lib\\site-packages\\litemind\\apis\\providers\\ollama\\utils\\list_models.py\", line 7, in _get_ollama_models_list\n",
      "    model_list = list(client.list().models)\n",
      "  File \"c:\\Users\\dario\\anaconda3\\envs\\masterThesis\\lib\\site-packages\\ollama\\_client.py\", line 567, in list\n",
      "    return self._request(\n",
      "  File \"c:\\Users\\dario\\anaconda3\\envs\\masterThesis\\lib\\site-packages\\ollama\\_client.py\", line 178, in _request\n",
      "    return cls(**self._request_raw(*args, **kwargs).json())\n",
      "  File \"c:\\Users\\dario\\anaconda3\\envs\\masterThesis\\lib\\site-packages\\ollama\\_client.py\", line 124, in _request_raw\n",
      "    raise ConnectionError(CONNECTION_ERROR_MESSAGE) from None\n",
      "ConnectionError: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├ API OllamaApi could not be instantiated: Error initializing Ollama client: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download. Removing it from the list.\n",
      "├ API GeminiApi could not be instantiated: A valid GOOGLE_API_KEY is required for GeminiApi. Set GOOGLE_API_KEY in the environment or pass api_key explicitly.. Removing it from the list.\n"
     ]
    }
   ],
   "source": [
    "from litemind.apis.combined_api import CombinedApi\n",
    "from litemind.agent.tools.toolset import ToolSet\n",
    "from litemind.apis.providers.openai.openai_api import OpenAIApi\n",
    "from litemind.agent.agent import Agent\n",
    "\n",
    "\n",
    "import pymmcore_plus\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# install local openai\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import google\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap(core: pymmcore_plus.CMMCorePlus.instance()):\n",
    "\n",
    "    # snap and image\n",
    "    core.snapImage()\n",
    "\n",
    "    return core.getImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a tool to snap an image\n",
    "def get_image(request: str) -> np.array:\n",
    "    \"\"\" The microscope return the image as an array \"\"\"\n",
    "    from pymmcore_plus import CMMCorePlus\n",
    "\n",
    "    core = CMMCorePlus()\n",
    "    # load configuration\n",
    "    core.loadSystemConfiguration()\n",
    "    \n",
    "    # return the array with the snapped image\n",
    "    return snap(core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├╗ Calling agent: 'Agent'\n",
      "│├╗ API and model:\n",
      "││├ API: OpenAIApi\n",
      "││├ Model: gpt-4o-mini\n",
      "││┴« 5.35 milliseconds\n",
      "││\n",
      "│├╗ Available tools\n",
      "││├ get_image(request: string) % The microscope return the image as an array \n",
      "││┴« 3.00 milliseconds\n",
      "││\n",
      "│├╗ Last message in conversation:\n",
      "││├ *user*:\n",
      "│││ Take an image of the sample.\n",
      "││┴« 5.00 milliseconds\n",
      "││\n",
      "│├╗ Executing tool 'get_image'\n",
      "││├ Arguments: (), {'request': 'Take an image of the sample.'}\n",
      "││├ Result: [[3276 3339 3402 ... 3087 3150 3213]\n",
      "│││  [3284 3347 3410 ... 3095 3158 3221]\n",
      "│││  [3292 3355 3418 ... 3103 3166 3229]\n",
      "│││  ...\n",
      "│││  [5846 5846 5844 ... 5837 5842 5845]\n",
      "│││  [5846 5846 5844 ... 5838 5842 5845]\n",
      "│││  [5846 5846 5843 ... 5839 5843 5845]]\n",
      "││┴« 125.25 milliseconds\n",
      "││\n",
      "│├╗ Reponse:\n",
      "││├ *assistant*:\n",
      "│││ TOOL: get_image(request=Take an image of the sample.)\n",
      "││├ *user*:\n",
      "│││ TOOL: get_image(request=Take an image of the sample.)=\"[[3276 3339 3402 ... 3087 3150 3213]\\n [3284 3347 3410 ... 3095 3158 3221]\\n [3292 3355 3418 ... 3103 3166 3229]\\n ...\\n [5846 5846 5844 ... 5837 5842 5845]\\n [5846 5846 5844 ... 5838 5842 5845]\\n [5846 5846 5843 ... 5839 5843 5845]]\"\n",
      "││├ *assistant*:\n",
      "│││ I have taken an image of the sample. The image data is represented as a 2D array of pixel values. If you need further analysis or processing of this image, please let me know!\n",
      "││┴« 26.94 milliseconds\n",
      "││\n",
      "│┴« 2.14 seconds\n",
      "│\n",
      "*assistant*:\n",
      "I have taken an image of the sample. The image data is represented as a 2D array of pixel values. If you need further analysis or processing of this image, please let me know!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a toolset and add the function tool\n",
    "toolset = ToolSet()\n",
    "toolset.add_function_tool(get_image)\n",
    "\n",
    "api = OpenAIApi()\n",
    "agent = Agent(api=api, toolset= toolset,model_name=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "# Add a system message to define the agent's behavior\n",
    "agent.append_system_message(\"You are a helpful scientist assistant.\")\n",
    "\n",
    "# Run the agent with a user query\n",
    "response = agent(\"Take an image of the sample.\")\n",
    "\n",
    "# Print the response\n",
    "print(response[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*assistant*:\n",
      "I'm sorry, but I can't take or display images. However, I can help you with descriptions, explanations, or any information you need. Let me know how I can assist you!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from litemind.agent.messages.message import Message\n",
    "\n",
    "# Create messages\n",
    "system_message = Message(role=\"system\", text=\"You are a helpful assistant.\")\n",
    "user_message = Message(role=\"user\", text=\"Take an image of the sample.\")\n",
    "\n",
    "# Generate a response\n",
    "response = api.generate_text(messages=[system_message, user_message],model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# Print the response\n",
    "print(response[0])\n",
    "# Expected output: \"The capital of France is Paris.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterThesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
